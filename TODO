# Slack Notifications Intergration 

1. Set up Slack API Integration:
   - Create a Slack App in the Slack API dashboard (api.slack.com)
   - Set up appropriate permissions (chat:write, files:write)
   - Generate and securely store OAuth tokens
   - Add to environment variables (SLACK_API_TOKEN, SLACK_CHANNEL_ID)

2. Create a Slack Notification Module (scripts/slack_notifier.py):
   - Implement function to send basic text notifications
   - Implement function to upload and share resume/cover letter PDFs
   - Implement function to send job application summaries with links

3. Integrate with Document Generation Process:
   - Modify generate_documents.py to call Slack notification functions
   - Send notification when new resume/cover letter is generated
   - Include job title, company, and match score in the notification
   - Upload generated PDFs as attachments

4. Create Job Application Status Dashboard in Slack:
   - Daily summary of pending applications
   - Notifications for status changes
   - Reminders for follow-ups

5. Add Command-line Options:
   - Make Slack notifications optional via command line flags
   - Allow specifying different channels for different notification types

6. Security Considerations:
   - Store API tokens securely
   - Ensure no sensitive personal information is shared in public channels
   - Implement rate limiting to avoid API throttling

# Slackbot Integration and Cloud Function Enhancements

## File Retrieval for Slackbot

### Overview
Enable Slackbot to retrieve files from Google Cloud Storage (GCS) and present them in Slack:
- **Markdown Files (`.md`)**: Display the content directly in Slack as rendered Markdown.
- **PDF Files (`.pdf`)**: Upload the file to Slack as an attachment.

### Implementation Steps
1. **Slack Command**:
   - Add a new slash command `/get-file` in the Slack app configuration.
   - Set the request URL to the Cloud Function's endpoint.

2. **Cloud Function Logic**:
   - Fetch the file from GCS based on the file name provided in the Slack command.
   - For Markdown files:
     - Download the content from GCS.
     - Use Slack's `mrkdwn` block type to render the content directly in Slack.
   - For PDF files:
     - Download the file to a temporary directory.
     - Upload the file to Slack as an attachment using the `files_upload` API.
   - For unsupported file types:
     - Send an error message to Slack.

3. **Example Slack Interaction**:
   - **User Input**: `/get-file strategy_2025-04-20.md`
   - **Bot Response**: Render the Markdown content directly in Slack.
   - **User Input**: `/get-file resume.pdf`
   - **Bot Response**: Upload the `resume.pdf` file to Slack as an attachment.

---

## Converting GitHub Actions to Cloud Functions with Slackbot Commands

### Actions to Convert
1. **Job Strategy Generation**:
   - **Command**: `/generate-strategy`
   - **Options**:
     - `job_limit`: Number of jobs per search query (default: 5).
     - `include_recruiters`: Include recruiter information (default: false).
     - `generate_documents`: Generate application documents (default: false).
     - `generate_article`: Generate a Medium article (default: false).
     - `preview_article`: Generate a Medium article in preview mode (default: false).
   - **Examples**:
     - `/generate-strategy`
     - `/generate-strategy job_limit:10`
     - `/generate-strategy include_recruiters:true`

2. **Medium Article Generation**:
   - **Command**: `/generate-article`
   - **Options**:
     - `skill`: Focus the article on a specific skill.
     - `preview`: Generate the article in preview mode (default: false).
   - **Examples**:
     - `/generate-article`
     - `/generate-article skill:Python`
     - `/generate-article preview:true`

3. **Profile Data Management**:
   - **Commands**:
     - `/update-profile`: Update LinkedIn profile data.
     - `/update-resume`: Update resume data.
     - `/update-cover-letter`: Update cover letter data.
     - `/combine-profile-data`: Combine and summarize all profile data.

4. **GitHub Pages Deployment**:
   - **Command**: `/deploy-pages`
   - **Description**: Deploy the GitHub Pages site with the latest updates.

5. **Strategy File Cleanup**:
   - **Command**: `/cleanup-strategies`
   - **Options**:
     - `retention_days`: Number of days to retain files (default: 7).
   - **Examples**:
     - `/cleanup-strategies`
     - `/cleanup-strategies retention_days:30`

---

## Setting Up the Slackbot

### 1. Create a Slack App
- Go to [Slack API Dashboard](https://api.slack.com/apps) and create a new app.
- Enable the following features:
  - **Slash Commands**: Add commands like `/generate-strategy` and `/get-file`.
  - **Interactive Components**: Enable for buttons, dropdowns, etc.

### 2. Configure Permissions
- Add the following OAuth scopes:
  - `chat:write`
  - `files:write`
  - `commands`

### 3. Set Up Environment Variables
- Add the following environment variables to the Cloud Functions:
  - `SLACK_API_TOKEN`: OAuth token for the Slack bot.
  - `GCS_BUCKET_NAME`: Name of the GCS bucket where files are stored.

### 4. Deployment Configuration
- Update `cloudbuild.yaml` to include the environment variables:
  ```yaml
  steps:
    - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
      args:
        - gcloud
        - functions
        - deploy
        - generate-job-strategy
        - --runtime=python39
        - --trigger-http
        - --set-env-vars=SLACK_API_TOKEN=${_SLACK_API_TOKEN},GCS_BUCKET_NAME=${_GCS_BUCKET_NAME}
  ```

### 5. Testing
- Test each Slack command to ensure proper functionality:
  - Verify file retrieval for Markdown and PDF files.
  - Verify job strategy generation and other actions.

---

## Additional Features

### Slack Notifications
- **Resume Generation**:
  - Notify when a new resume or cover letter is generated.
  - Include job title, company, and match score in the notification.
  - Upload generated PDFs as attachments.
- **Job Application Status Dashboard**:
  - Daily summary of pending applications.
  - Notifications for status changes.
  - Reminders for follow-ups.

### Security Considerations
- Store API tokens securely.
- Ensure no sensitive personal information is shared in public channels.
- Implement rate limiting to avoid API throttling.

# Secrets Management

## Overview
Properly managing secrets is critical to ensure the security of sensitive information such as API keys, tokens, and credentials. This section outlines the steps to identify, organize, and migrate secrets to Google Secret Manager.

### Current Secrets
The following secrets are currently in use across the project:

#### `.env` File Secrets
- `GEMINI_API_KEY`: API key for Google Gemini.
- `MEDIUM_API_TOKEN`: API token for Medium.
- `GCS_BUCKET_NAME`: Name of the Google Cloud Storage bucket.
- `SLACK_API_TOKEN`: OAuth token for the Slack bot.
- `SLACK_CHANNEL_ID`: Default Slack channel ID for notifications.

#### GitHub Repository Secrets
- `GITHUB_TOKEN`: Token for GitHub Actions.
- `GOOGLE_CREDENTIALS`: JSON credentials for Google Cloud authentication.

### Migration to Google Secret Manager
1. **Identify All Secrets**:
   - Audit the `.env` file and GitHub repository secrets to ensure all secrets are accounted for.

2. **Create Secrets in Google Secret Manager**:
   - Use the Google Cloud Console or CLI to create secrets for each key.
   - Example CLI command:
     ```bash
     gcloud secrets create GEMINI_API_KEY --data-file=.env
     ```

3. **Update Cloud Functions**:
   - Modify the Cloud Functions to fetch secrets from Google Secret Manager instead of environment variables.
   - Use the `google-cloud-secretmanager` library to access secrets.
   - Example:
     ```python
     from google.cloud import secretmanager

     def get_secret(secret_name):
         client = secretmanager.SecretManagerServiceClient()
         name = f"projects/<project-id>/secrets/{secret_name}/versions/latest"
         response = client.access_secret_version(request={"name": name})
         return response.payload.data.decode("UTF-8")
     ```

4. **Update GitHub Actions**:
   - Replace GitHub repository secrets with references to Google Secret Manager.
   - Use the `google-github-actions/auth` action to authenticate with Google Cloud.
   - Example:
     ```yaml
     - name: Authenticate to Google Cloud
       uses: google-github-actions/auth@v0
       with:
         credentials_json: ${{ secrets.GOOGLE_CREDENTIALS }}

     - name: Access Secret
       run: |
         gcloud secrets versions access latest --secret="GEMINI_API_KEY"
     ```

5. **Secure Local Development**:
   - Use a `.env.local` file for local development.
   - Ensure `.env.local` is added to `.gitignore` to prevent accidental commits.

6. **Audit and Remove Legacy Secrets**:
   - Verify that all secrets are successfully migrated.
   - Remove secrets from `.env` and GitHub repository once migration is complete.

### Best Practices
- **Access Control**: Limit access to secrets based on the principle of least privilege.
- **Rotation**: Regularly rotate secrets to minimize the impact of potential leaks.
- **Monitoring**: Enable logging and monitoring for secret access to detect unauthorized usage.
- **Encryption**: Ensure all secrets are encrypted at rest and in transit.

### Next Steps
1. Create a list of all secrets currently in use.
2. Migrate secrets to Google Secret Manager.
3. Update Cloud Functions and GitHub Actions to use Google Secret Manager.
4. Test the updated configuration to ensure functionality.
5. Remove legacy secrets from `.env` and GitHub repository.

# analyze_job_with_gemini
Gemini doesn't have enough information in its prompt to be able really analyze the job. 
We haven't told it which criteri to judge by.


# current errors
there's some weird stuff happening with the formatting here, the description has location and post date in the same string. the description should be locaition and the data should be split so that the post date gets its own field in the json. 

# code sanity
I'm pretty sure we're having Gemini return structured data, lets make sure that it's aware of this. Please find all Gemini queries that are not explicitly defining the structure of it's returned data. 


# Glassdoor

Adding Glassdoor Company Research to Job Analysis
I can implement a feature to search for company information on Glassdoor as part of the job analysis process. This would enrich the company_overview section with more accurate data based on Glassdoor's company profiles.


Now, let's update the job analysis function to incorporate this company research:

Finally, let's make sure the UI displays this additional company information:

Benefits of this Implementation:
Enhanced Company Insights: Job seekers get valuable information about potential employers
Better Decision Making: More context about company size, industry, and stability
Reduced Research Time: Automatic compilation of company information
This implementation uses Gemini to search for public information about companies, pulling data from various sources including Glassdoor, LinkedIn, and company websites, then structured into a consistent format for your job search.


# Migrations
## target_roles
* WARNING: Error accessing database for target roles: (sqlite3.OperationalError) no such column: target_roles.requirements
[SQL: SELECT target_roles.id AS target_roles_id, target_roles.role_name AS target_roles_role_name, target_roles.priority AS target_roles_priority, target_roles.match_score AS target_roles_match_score, target_roles.reasoning AS target_roles_reasoning, target_roles.source AS target_roles_source, target_roles.last_updated AS target_roles_last_updated, target_roles.requirements AS target_roles_requirements, target_roles.next_steps AS target_roles_next_steps 

## cached jobs
ERROR: Error retrieving cached jobs: (sqlite3.OperationalError) no such column: job_cache.location
[SQL: SELECT job_cache.id AS job_cache_id, job_cache.url AS job_cache_url, job_cache.title AS job_cache_title, job_cache.company AS job_cache_company, job_cache.description AS job_cache_description, job_cache.location AS job_cache_location, job_cache.post_date AS job_cache_post_date, job_cache.first_seen_date AS job_cache_first_seen_date, job_cache.last_seen_date AS job_cache_last_seen_date, job_cache.match_score AS job_cache_match_score, job_cache.application_priority AS job_cache_application_priority, job_cache.key_requirements AS job_cache_key_requirements, job_cache.culture_indicators AS job_cache_culture_indicators, job_cache.career_growth_potential AS job_cache_career_growth_potential, job_cache.search_query AS job_cache_search_query, job_cache.total_years_experience AS job_cache_total_years_experience, job_cache.candidate_gaps AS job_cache_candidate_gaps, job_cache.location_type AS job_cache_location_type, job_cache.company_size AS job_cache_company_size, job_cache.company_stability AS job_cache_company_stability, job_cache.glassdoor_rating AS job_cache_glassdoor_rating, job_cache.employee_count AS job_cache_employee_count, job_cache.year_founded AS job_cache_year_founded, job_cache.growth_stage AS job_cache_growth_stage, job_cache.market_position AS job_cache_market_position, job_cache.development_opportunities AS job_cache_development_opportunities 